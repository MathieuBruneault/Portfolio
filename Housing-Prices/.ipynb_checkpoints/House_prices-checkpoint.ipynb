{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting House Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data as pandas array and make a dict of keras inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv(\"../Data/house_prices/train.csv\")\n",
    "cutoff = 7 * len(full_data) // 10\n",
    "\n",
    "train_data = full_data[:cutoff]\n",
    "features = train_data.copy()\n",
    "labels = np.array(features.pop('SalePrice')) / 100000\n",
    "features.pop('Id')\n",
    "\n",
    "test_data = full_data[cutoff:]\n",
    "test_features = test_data.copy()\n",
    "test_labels = np.array(test_features.pop('SalePrice')) / 100000\n",
    "test_features.pop('Id')\n",
    "\n",
    "inputs = {}\n",
    "year_cols=['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold']\n",
    "\n",
    "for col in year_cols:\n",
    "    features[col] = features[col].astype(str)\n",
    "    test_features[col] = test_features[col].astype(str)\n",
    "\n",
    "for name, column in features.items():\n",
    "    dtype = column.dtype\n",
    "    if dtype == object:\n",
    "        dtype = tf.string\n",
    "        features[name] = features[name].fillna('NO INFO')\n",
    "    else:\n",
    "        dtype = tf.float32\n",
    "        features[name] = features[name].fillna(features[name].mean(axis=0))\n",
    "\n",
    "    inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "test_inputs = {}\n",
    "\n",
    "for name, column in test_features.items():\n",
    "    dtype = column.dtype\n",
    "    if dtype == object:\n",
    "        dtype = tf.string\n",
    "        test_features[name] = test_features[name].fillna('NO INFO')\n",
    "    else:\n",
    "        dtype = tf.float32\n",
    "        test_features[name] = test_features[name].fillna(test_features[name].mean(axis=0))\n",
    "\n",
    "    test_inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate and normalize the float/integer inputs through appropriate layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = layers.Normalization()\n",
    "norm.adapt(np.array(features[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the string inputs, by passing through a StringLookup and CategoryEncoding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, inpt in inputs.items():\n",
    "    if inpt.dtype == tf.float32:\n",
    "        continue\n",
    "    lookup = layers.StringLookup(vocabulary=np.unique(features[name]))\n",
    "    one_hot = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "\n",
    "    x = lookup(inpt)\n",
    "    x = one_hot(x)\n",
    "    preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "preprocessing_model = tf.keras.Model(inputs, preprocessed_inputs_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {name: np.array(value) \n",
    "                for name, value in features.items()}\n",
    "test_features_dict = {name: np.array(value) \n",
    "                    for name, value in test_features.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the first model: Keras neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with a simple model, with one hidden layer of 40 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_model(preprocessing, inputs):\n",
    "    main = tf.keras.Sequential([\n",
    "        layers.Dense(40, activation='relu'),\n",
    "        layers.Dropout(.2, input_shape=(2,)),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    preprocessed_inputs = preprocessing(inputs)\n",
    "    result = main(preprocessed_inputs)\n",
    "    model = tf.keras.Model(inputs, result)\n",
    "\n",
    "    model.compile(loss=tf.losses.MeanSquaredLogarithmicError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                 metrics=['MeanAbsolutePercentageError', 'MSLE'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callbacks(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_losses.append(logs['mean_absolute_percentage_error'])\n",
    "        epochs_list.append(epoch)\n",
    "        test_losses.append(self.model.evaluate(test_features_dict, test_labels)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "14/14 [==============================] - 1s 3ms/step - loss: 0.0272 - mean_absolute_percentage_error: 22.1772 - MSLE: 0.0272\n",
      "32/32 [==============================] - 4s 56ms/step - loss: 0.1433 - mean_absolute_percentage_error: 46.8149 - MSLE: 0.1433\n",
      "Epoch 2/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0188 - mean_absolute_percentage_error: 17.6240 - MSLE: 0.0188\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0299 - mean_absolute_percentage_error: 22.3442 - MSLE: 0.0299\n",
      "Epoch 3/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0150 - mean_absolute_percentage_error: 14.9864 - MSLE: 0.0150\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0250 - mean_absolute_percentage_error: 19.8083 - MSLE: 0.0250\n",
      "Epoch 4/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0133 - mean_absolute_percentage_error: 13.4892 - MSLE: 0.0133\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0220 - mean_absolute_percentage_error: 19.5346 - MSLE: 0.0220\n",
      "Epoch 5/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0126 - mean_absolute_percentage_error: 12.9205 - MSLE: 0.0126\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0178 - mean_absolute_percentage_error: 16.7421 - MSLE: 0.0178\n",
      "Epoch 6/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0122 - mean_absolute_percentage_error: 12.8521 - MSLE: 0.0122\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0177 - mean_absolute_percentage_error: 16.7213 - MSLE: 0.0177\n",
      "Epoch 7/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0121 - mean_absolute_percentage_error: 12.7990 - MSLE: 0.0121\n",
      "32/32 [==============================] - 2s 67ms/step - loss: 0.0154 - mean_absolute_percentage_error: 15.6756 - MSLE: 0.0154\n",
      "Epoch 8/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0112 - mean_absolute_percentage_error: 11.9865 - MSLE: 0.0112\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0147 - mean_absolute_percentage_error: 15.2826 - MSLE: 0.0147\n",
      "Epoch 9/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0114 - mean_absolute_percentage_error: 12.4459 - MSLE: 0.0114\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0152 - mean_absolute_percentage_error: 15.6201 - MSLE: 0.0152\n",
      "Epoch 10/80\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0112 - mean_absolute_percentage_error: 12.3583 - MSLE: 0.0112\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0133 - mean_absolute_percentage_error: 14.9077 - MSLE: 0.0133\n",
      "Epoch 11/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0111 - mean_absolute_percentage_error: 12.1555 - MSLE: 0.0111\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0135 - mean_absolute_percentage_error: 14.5430 - MSLE: 0.0135\n",
      "Epoch 12/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0106 - mean_absolute_percentage_error: 11.3409 - MSLE: 0.0106\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0138 - mean_absolute_percentage_error: 14.7333 - MSLE: 0.0138\n",
      "Epoch 13/80\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0107 - mean_absolute_percentage_error: 11.7628 - MSLE: 0.0107\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0141 - mean_absolute_percentage_error: 15.2564 - MSLE: 0.0141\n",
      "Epoch 14/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0106 - mean_absolute_percentage_error: 11.9031 - MSLE: 0.0106\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0133 - mean_absolute_percentage_error: 14.3365 - MSLE: 0.0133\n",
      "Epoch 15/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0105 - mean_absolute_percentage_error: 11.7669 - MSLE: 0.0105\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0122 - mean_absolute_percentage_error: 13.8769 - MSLE: 0.0122\n",
      "Epoch 16/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0107 - mean_absolute_percentage_error: 12.1155 - MSLE: 0.0107\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0115 - mean_absolute_percentage_error: 13.3510 - MSLE: 0.0115\n",
      "Epoch 17/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0102 - mean_absolute_percentage_error: 11.2564 - MSLE: 0.0102\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0124 - mean_absolute_percentage_error: 13.7223 - MSLE: 0.0124\n",
      "Epoch 18/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0104 - mean_absolute_percentage_error: 11.8294 - MSLE: 0.0104\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0116 - mean_absolute_percentage_error: 13.5598 - MSLE: 0.0116\n",
      "Epoch 19/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0104 - mean_absolute_percentage_error: 11.7382 - MSLE: 0.0104\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0128 - mean_absolute_percentage_error: 13.8904 - MSLE: 0.0128\n",
      "Epoch 20/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0100 - mean_absolute_percentage_error: 11.2588 - MSLE: 0.0100\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0112 - mean_absolute_percentage_error: 13.2904 - MSLE: 0.0112\n",
      "Epoch 21/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0101 - mean_absolute_percentage_error: 11.2803 - MSLE: 0.0101\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0098 - mean_absolute_percentage_error: 12.2004 - MSLE: 0.0098\n",
      "Epoch 22/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0117 - mean_absolute_percentage_error: 13.1689 - MSLE: 0.0117\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 0.0119 - mean_absolute_percentage_error: 13.2351 - MSLE: 0.0119\n",
      "Epoch 23/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0102 - mean_absolute_percentage_error: 11.5151 - MSLE: 0.0102\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0100 - mean_absolute_percentage_error: 12.6778 - MSLE: 0.0100\n",
      "Epoch 24/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0106 - mean_absolute_percentage_error: 12.1340 - MSLE: 0.0106\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0101 - mean_absolute_percentage_error: 12.4605 - MSLE: 0.0101\n",
      "Epoch 25/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0103 - mean_absolute_percentage_error: 11.5086 - MSLE: 0.0103\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0103 - mean_absolute_percentage_error: 12.7730 - MSLE: 0.0103\n",
      "Epoch 26/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0104 - mean_absolute_percentage_error: 12.2442 - MSLE: 0.0104\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0103 - mean_absolute_percentage_error: 12.9167 - MSLE: 0.0103\n",
      "Epoch 27/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0101 - mean_absolute_percentage_error: 11.4110 - MSLE: 0.0101\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0102 - mean_absolute_percentage_error: 12.6422 - MSLE: 0.0102\n",
      "Epoch 28/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0098 - mean_absolute_percentage_error: 11.1751 - MSLE: 0.0098\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0103 - mean_absolute_percentage_error: 12.8214 - MSLE: 0.0103\n",
      "Epoch 29/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0099 - mean_absolute_percentage_error: 11.6441 - MSLE: 0.0099\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0096 - mean_absolute_percentage_error: 12.2205 - MSLE: 0.0096\n",
      "Epoch 30/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0096 - mean_absolute_percentage_error: 10.8320 - MSLE: 0.0096\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0093 - mean_absolute_percentage_error: 12.2098 - MSLE: 0.0093\n",
      "Epoch 31/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0100 - mean_absolute_percentage_error: 11.5931 - MSLE: 0.0100\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0094 - mean_absolute_percentage_error: 11.8771 - MSLE: 0.0094\n",
      "Epoch 32/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0100 - mean_absolute_percentage_error: 11.9148 - MSLE: 0.0100\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0098 - mean_absolute_percentage_error: 12.1270 - MSLE: 0.0098\n",
      "Epoch 33/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0096 - mean_absolute_percentage_error: 11.1674 - MSLE: 0.0096\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0093 - mean_absolute_percentage_error: 11.9527 - MSLE: 0.0093\n",
      "Epoch 34/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0096 - mean_absolute_percentage_error: 11.4304 - MSLE: 0.0096\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0090 - mean_absolute_percentage_error: 11.5747 - MSLE: 0.0090\n",
      "Epoch 35/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0091 - mean_absolute_percentage_error: 10.6373 - MSLE: 0.0091\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0087 - mean_absolute_percentage_error: 11.7408 - MSLE: 0.0087\n",
      "Epoch 36/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0095 - mean_absolute_percentage_error: 10.9583 - MSLE: 0.0095\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0084 - mean_absolute_percentage_error: 11.2856 - MSLE: 0.0084\n",
      "Epoch 37/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0093 - mean_absolute_percentage_error: 11.0048 - MSLE: 0.0093\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0091 - mean_absolute_percentage_error: 12.0387 - MSLE: 0.0091\n",
      "Epoch 38/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0094 - mean_absolute_percentage_error: 11.5422 - MSLE: 0.0094\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0079 - mean_absolute_percentage_error: 11.0060 - MSLE: 0.0079\n",
      "Epoch 39/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_absolute_percentage_error: 10.6940 - MSLE: 0.0090\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0089 - mean_absolute_percentage_error: 11.8660 - MSLE: 0.0089\n",
      "Epoch 40/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_absolute_percentage_error: 10.9566 - MSLE: 0.0088\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0078 - mean_absolute_percentage_error: 10.9165 - MSLE: 0.0078\n",
      "Epoch 41/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0100 - mean_absolute_percentage_error: 11.7982 - MSLE: 0.0100\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0088 - mean_absolute_percentage_error: 11.6493 - MSLE: 0.0088\n",
      "Epoch 42/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0092 - mean_absolute_percentage_error: 11.3344 - MSLE: 0.0092\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0077 - mean_absolute_percentage_error: 11.1377 - MSLE: 0.0077\n",
      "Epoch 43/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0092 - mean_absolute_percentage_error: 11.0688 - MSLE: 0.0092\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0085 - mean_absolute_percentage_error: 11.4294 - MSLE: 0.0085\n",
      "Epoch 44/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0095 - mean_absolute_percentage_error: 11.3073 - MSLE: 0.0095\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0083 - mean_absolute_percentage_error: 11.2868 - MSLE: 0.0083\n",
      "Epoch 45/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0092 - mean_absolute_percentage_error: 11.1824 - MSLE: 0.0092\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0083 - mean_absolute_percentage_error: 11.2396 - MSLE: 0.0083\n",
      "Epoch 46/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_absolute_percentage_error: 11.0037 - MSLE: 0.0090\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0073 - mean_absolute_percentage_error: 10.6374 - MSLE: 0.0073\n",
      "Epoch 47/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_absolute_percentage_error: 10.8951 - MSLE: 0.0090\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0074 - mean_absolute_percentage_error: 10.6456 - MSLE: 0.0074\n",
      "Epoch 48/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0086 - mean_absolute_percentage_error: 10.7138 - MSLE: 0.0086\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0075 - mean_absolute_percentage_error: 10.7819 - MSLE: 0.0075\n",
      "Epoch 49/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0086 - mean_absolute_percentage_error: 10.7461 - MSLE: 0.0086\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0073 - mean_absolute_percentage_error: 10.3784 - MSLE: 0.0073\n",
      "Epoch 50/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0093 - mean_absolute_percentage_error: 11.6599 - MSLE: 0.0093\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0071 - mean_absolute_percentage_error: 10.4279 - MSLE: 0.0071\n",
      "Epoch 51/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_absolute_percentage_error: 10.9561 - MSLE: 0.0090\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0075 - mean_absolute_percentage_error: 10.8775 - MSLE: 0.0075\n",
      "Epoch 52/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0086 - mean_absolute_percentage_error: 10.6928 - MSLE: 0.0086\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0070 - mean_absolute_percentage_error: 10.2658 - MSLE: 0.0070\n",
      "Epoch 53/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0095 - mean_absolute_percentage_error: 11.8007 - MSLE: 0.0095\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0072 - mean_absolute_percentage_error: 10.3525 - MSLE: 0.0072\n",
      "Epoch 54/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0089 - mean_absolute_percentage_error: 11.3157 - MSLE: 0.0089\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0071 - mean_absolute_percentage_error: 10.3887 - MSLE: 0.0071\n",
      "Epoch 55/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_absolute_percentage_error: 10.7317 - MSLE: 0.0088\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0067 - mean_absolute_percentage_error: 10.0519 - MSLE: 0.0067\n",
      "Epoch 56/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0086 - mean_absolute_percentage_error: 10.5783 - MSLE: 0.0086\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0069 - mean_absolute_percentage_error: 10.2680 - MSLE: 0.0069\n",
      "Epoch 57/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0086 - mean_absolute_percentage_error: 10.8012 - MSLE: 0.0086\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0063 - mean_absolute_percentage_error: 9.9732 - MSLE: 0.0063\n",
      "Epoch 58/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_absolute_percentage_error: 10.9046 - MSLE: 0.0088\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0066 - mean_absolute_percentage_error: 10.0107 - MSLE: 0.0066\n",
      "Epoch 59/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.6731 - MSLE: 0.0085\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0062 - mean_absolute_percentage_error: 9.8673 - MSLE: 0.0062\n",
      "Epoch 60/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0087 - mean_absolute_percentage_error: 10.8169 - MSLE: 0.0087\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0063 - mean_absolute_percentage_error: 9.5985 - MSLE: 0.0063\n",
      "Epoch 61/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0086 - mean_absolute_percentage_error: 10.7958 - MSLE: 0.0086\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 9.1224 - MSLE: 0.0058\n",
      "Epoch 62/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.6646 - MSLE: 0.0085\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0059 - mean_absolute_percentage_error: 9.3851 - MSLE: 0.0059\n",
      "Epoch 63/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0081 - mean_absolute_percentage_error: 10.5068 - MSLE: 0.0081\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0062 - mean_absolute_percentage_error: 9.3201 - MSLE: 0.0062\n",
      "Epoch 64/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_absolute_percentage_error: 10.7624 - MSLE: 0.0084\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0060 - mean_absolute_percentage_error: 9.2044 - MSLE: 0.0060\n",
      "Epoch 65/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 10.6823 - MSLE: 0.0083\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0056 - mean_absolute_percentage_error: 9.1555 - MSLE: 0.0056\n",
      "Epoch 66/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.5218 - MSLE: 0.0085\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 9.3166 - MSLE: 0.0058\n",
      "Epoch 67/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0082 - mean_absolute_percentage_error: 10.4291 - MSLE: 0.0082\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0062 - mean_absolute_percentage_error: 9.2923 - MSLE: 0.0062\n",
      "Epoch 68/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_absolute_percentage_error: 10.5472 - MSLE: 0.0084\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0057 - mean_absolute_percentage_error: 9.2624 - MSLE: 0.0057\n",
      "Epoch 69/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0081 - mean_absolute_percentage_error: 10.4194 - MSLE: 0.0081\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0054 - mean_absolute_percentage_error: 8.9574 - MSLE: 0.0054\n",
      "Epoch 70/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 10.5506 - MSLE: 0.0083\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 0.0056 - mean_absolute_percentage_error: 9.2620 - MSLE: 0.0056\n",
      "Epoch 71/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0081 - mean_absolute_percentage_error: 10.4005 - MSLE: 0.0081\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0054 - mean_absolute_percentage_error: 9.1814 - MSLE: 0.0054\n",
      "Epoch 72/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.6004 - MSLE: 0.0085\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0052 - mean_absolute_percentage_error: 8.5713 - MSLE: 0.0052\n",
      "Epoch 73/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_absolute_percentage_error: 10.6715 - MSLE: 0.0084\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0053 - mean_absolute_percentage_error: 9.0062 - MSLE: 0.0053\n",
      "Epoch 74/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0091 - mean_absolute_percentage_error: 10.9892 - MSLE: 0.0091\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0057 - mean_absolute_percentage_error: 9.0658 - MSLE: 0.0057\n",
      "Epoch 75/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_absolute_percentage_error: 10.5219 - MSLE: 0.0084\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0051 - mean_absolute_percentage_error: 8.8058 - MSLE: 0.0051\n",
      "Epoch 76/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 10.3082 - MSLE: 0.0083\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 9.0451 - MSLE: 0.0058\n",
      "Epoch 77/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.5834 - MSLE: 0.0085\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0046 - mean_absolute_percentage_error: 8.2748 - MSLE: 0.0046\n",
      "Epoch 78/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 10.3938 - MSLE: 0.0083\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0059 - mean_absolute_percentage_error: 9.0759 - MSLE: 0.0059\n",
      "Epoch 79/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 10.5288 - MSLE: 0.0083\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0053 - mean_absolute_percentage_error: 8.5945 - MSLE: 0.0053\n",
      "Epoch 80/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0087 - mean_absolute_percentage_error: 10.9867 - MSLE: 0.0087\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0054 - mean_absolute_percentage_error: 8.6055 - MSLE: 0.0054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2efe0359e8>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "epochs_list = []\n",
    "model = first_model(preprocessing_model, inputs)\n",
    "model.fit(x=features_dict, y=labels, epochs=80, callbacks=[Callbacks()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "46.81486892700195"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(epochs_list, train_losses, label='Train')\n",
    "plt.plot(epochs_list, test_losses, label='Test')\n",
    "plt.legend()\n",
    "plt.ylim([0,1.15 * max(train_losses[0], test_losses[0])])\n",
    "plt.show()\n",
    "train_losses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0087 - mean_absolute_percentage_error: 10.9867 - MSLE: 0.0087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.008694416843354702, 10.98674488067627, 0.008694416843354702]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_features_dict, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_features_dict) * 100000\n",
    "actual = test_labels * 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.147])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_sum = 0\n",
    "for i in range(len(preds)):\n",
    "    tot_sum += (np.log(preds[i] + 1) - np.log(actual[i] + 1)) ** 2\n",
    "np.sqrt(tot_sum / len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New model: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it seems like it will be hard to reduce our bias with a neural network, we will turn to another model: random forests. We will do the same date pre-processing, but this time using pandas, since we will Scikit learn and not keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "full_data = pd.read_csv(\"../Data/house_prices/train.csv\")\n",
    "\n",
    "year_cols=['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold']\n",
    "\n",
    "for col in year_cols:\n",
    "    full_data[col] = full_data[col].astype(str)\n",
    "\n",
    "cutoff = 7 * len(full_data) // 10\n",
    "\n",
    "train_data = full_data[:cutoff]\n",
    "features = train_data.copy()\n",
    "labels = np.array(features.pop('SalePrice'))\n",
    "features.pop('Id')\n",
    "\n",
    "test_data = full_data[cutoff:]\n",
    "test_features = test_data.copy()\n",
    "test_labels = np.array(test_features.pop('SalePrice'))\n",
    "test_features.pop('Id')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PandasPreprocessing(features, train_data):  \n",
    "    year_cols=['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold']\n",
    "    for col in year_cols:\n",
    "        train_data[col] = train_data[col].astype(str)\n",
    "    for name, column in features.items():\n",
    "        dtype = column.dtype\n",
    "        if dtype == object:\n",
    "            features[name] = features[name].fillna('NO INFO')\n",
    "            train_data[name] = train_data[name].fillna('NO INFO')\n",
    "            enc = OneHotEncoder(handle_unknown='ignore')\n",
    "            enc.fit(train_data[name].to_numpy().reshape(-1, 1))\n",
    "            encoded_col = enc.transform(column.to_numpy().reshape(-1, 1)).toarray()\n",
    "            encoded_col = list(map(list, zip(*encoded_col)))\n",
    "            features.pop(name)\n",
    "            for i, col in enumerate(encoded_col):\n",
    "                features[name + '_' + str(i)] = col\n",
    "        else:\n",
    "            #No real need to normalize for tree based algorithms, just fill the nans with column mean\n",
    "            features[name] = features[name].fillna(features[name].mean(axis=0))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = PandasPreprocessing(features, train_data)\n",
    "test_features = PandasPreprocessing(test_features, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  9.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=1000,\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_state...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor()\n",
    "regr_random = RandomizedSearchCV(estimator = regr, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "regr_random.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 80,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=80,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=5,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=600,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor(n_estimators = 600,\n",
    " min_samples_split = 5,\n",
    " min_samples_leaf = 1,\n",
    " max_features = 'auto',\n",
    " max_depth = 80,\n",
    " bootstrap = True)\n",
    "regr.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = regr.predict(test_features)\n",
    "actual = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14946554434076403"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Desktoptot_sum = 0\n",
    "for i in range(len(preds)):\n",
    "    tot_sum += (np.log(preds[i] + 1) - np.log(actual[i] + 1)) ** 2\n",
    "np.sqrt(tot_sum / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
