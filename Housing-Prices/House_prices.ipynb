{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting House Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data as pandas array and make a dict of keras inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv(\"./Data/train.csv\")\n",
    "cutoff = 7 * len(full_data) // 10\n",
    "\n",
    "#Separate training and test data\n",
    "train_data = full_data[:cutoff]\n",
    "features = train_data.copy()\n",
    "labels = np.array(features.pop('SalePrice')) / 100000\n",
    "features.pop('Id')\n",
    "\n",
    "test_data = full_data[cutoff:]\n",
    "test_features = test_data.copy()\n",
    "test_labels = np.array(test_features.pop('SalePrice')) / 100000\n",
    "test_features.pop('Id')\n",
    "\n",
    "#Change the data type of the years to strings\n",
    "inputs = {}\n",
    "year_cols=['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold']\n",
    "\n",
    "for col in year_cols:\n",
    "    features[col] = features[col].astype(str)\n",
    "    test_features[col] = test_features[col].astype(str)\n",
    "\n",
    "#Deal with the missing data, either with a unique name for strings or the mean of the column for numbers\n",
    "for name, column in features.items():\n",
    "    dtype = column.dtype\n",
    "    if dtype == object:\n",
    "        dtype = tf.string\n",
    "        features[name] = features[name].fillna('NO INFO')\n",
    "    else:\n",
    "        dtype = tf.float32\n",
    "        features[name] = features[name].fillna(features[name].mean(axis=0))\n",
    "\n",
    "    inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "test_inputs = {}\n",
    "\n",
    "#Do the same processing for the test data\n",
    "for name, column in test_features.items():\n",
    "    dtype = column.dtype\n",
    "    if dtype == object:\n",
    "        dtype = tf.string\n",
    "        test_features[name] = test_features[name].fillna('NO INFO')\n",
    "    else:\n",
    "        dtype = tf.float32\n",
    "        test_features[name] = test_features[name].fillna(test_features[name].mean(axis=0))\n",
    "\n",
    "    test_inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate and normalize the float/integer inputs through appropriate layers to normalize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = layers.Normalization()\n",
    "norm.adapt(np.array(features[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the string inputs, by passing through a StringLookup and CategoryEncoding layer, for one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, inpt in inputs.items():\n",
    "    if inpt.dtype == tf.float32:\n",
    "        continue\n",
    "    lookup = layers.StringLookup(vocabulary=np.unique(features[name]))\n",
    "    one_hot = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "\n",
    "    x = lookup(inpt)\n",
    "    x = one_hot(x)\n",
    "    preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "preprocessing_model = tf.keras.Model(inputs, preprocessed_inputs_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {name: np.array(value) \n",
    "                for name, value in features.items()}\n",
    "test_features_dict = {name: np.array(value) \n",
    "                    for name, value in test_features.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the first model: Keras neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with a simple model, with one hidden layer of 40 nodes (more complex models were tried without much success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_model(preprocessing, inputs):\n",
    "    main = tf.keras.Sequential([\n",
    "        layers.Dense(40, activation='relu'),\n",
    "        layers.Dropout(.2, input_shape=(2,)),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    preprocessed_inputs = preprocessing(inputs)\n",
    "    result = main(preprocessed_inputs)\n",
    "    model = tf.keras.Model(inputs, result)\n",
    "\n",
    "    #The loss function will be based on the mean absolute percentage error\n",
    "    model.compile(loss=tf.losses.MeanSquaredLogarithmicError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                 metrics=['MeanAbsolutePercentageError', 'MSLE'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some callbacks, to save the training and test error on each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callbacks(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_losses.append(logs['mean_absolute_percentage_error'])\n",
    "        epochs_list.append(epoch)\n",
    "        test_losses.append(self.model.evaluate(test_features_dict, test_labels)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "14/14 [==============================] - 2s 3ms/step - loss: 0.0366 - mean_absolute_percentage_error: 30.0059 - MSLE: 0.0366\n",
      "32/32 [==============================] - 6s 59ms/step - loss: 0.2131 - mean_absolute_percentage_error: 46.6095 - MSLE: 0.2131\n",
      "Epoch 2/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0149 - mean_absolute_percentage_error: 14.8521 - MSLE: 0.0149\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0325 - mean_absolute_percentage_error: 23.6192 - MSLE: 0.0325\n",
      "Epoch 3/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0123 - mean_absolute_percentage_error: 13.1353 - MSLE: 0.0123\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0226 - mean_absolute_percentage_error: 19.6082 - MSLE: 0.0226\n",
      "Epoch 4/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0112 - mean_absolute_percentage_error: 12.4073 - MSLE: 0.0112\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0175 - mean_absolute_percentage_error: 16.6543 - MSLE: 0.0175\n",
      "Epoch 5/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0108 - mean_absolute_percentage_error: 12.3903 - MSLE: 0.0108\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0165 - mean_absolute_percentage_error: 16.2498 - MSLE: 0.0165\n",
      "Epoch 6/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0097 - mean_absolute_percentage_error: 11.1066 - MSLE: 0.0097\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0143 - mean_absolute_percentage_error: 14.8413 - MSLE: 0.0143\n",
      "Epoch 7/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0093 - mean_absolute_percentage_error: 10.7339 - MSLE: 0.0093\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0141 - mean_absolute_percentage_error: 14.5747 - MSLE: 0.0141\n",
      "Epoch 8/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0094 - mean_absolute_percentage_error: 10.9514 - MSLE: 0.0094\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0131 - mean_absolute_percentage_error: 13.8518 - MSLE: 0.0131\n",
      "Epoch 9/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0091 - mean_absolute_percentage_error: 10.2745 - MSLE: 0.0091\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0134 - mean_absolute_percentage_error: 13.9027 - MSLE: 0.0134\n",
      "Epoch 10/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_absolute_percentage_error: 10.2404 - MSLE: 0.0088\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0123 - mean_absolute_percentage_error: 13.1624 - MSLE: 0.0123\n",
      "Epoch 11/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_absolute_percentage_error: 10.2422 - MSLE: 0.0088\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0120 - mean_absolute_percentage_error: 13.6223 - MSLE: 0.0120\n",
      "Epoch 12/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_absolute_percentage_error: 10.2483 - MSLE: 0.0088\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0114 - mean_absolute_percentage_error: 12.9674 - MSLE: 0.0114\n",
      "Epoch 13/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0086 - mean_absolute_percentage_error: 10.0451 - MSLE: 0.0086\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0112 - mean_absolute_percentage_error: 12.7427 - MSLE: 0.0112\n",
      "Epoch 14/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0089 - mean_absolute_percentage_error: 10.4941 - MSLE: 0.0089\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0111 - mean_absolute_percentage_error: 12.7443 - MSLE: 0.0111\n",
      "Epoch 15/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0087 - mean_absolute_percentage_error: 10.0854 - MSLE: 0.0087\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0106 - mean_absolute_percentage_error: 12.3664 - MSLE: 0.0106\n",
      "Epoch 16/80\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0091 - mean_absolute_percentage_error: 10.6966 - MSLE: 0.0091\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0106 - mean_absolute_percentage_error: 12.3592 - MSLE: 0.0106\n",
      "Epoch 17/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0093 - mean_absolute_percentage_error: 11.3200 - MSLE: 0.0093\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0116 - mean_absolute_percentage_error: 12.8777 - MSLE: 0.0116\n",
      "Epoch 18/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0087 - mean_absolute_percentage_error: 10.2581 - MSLE: 0.0087\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0104 - mean_absolute_percentage_error: 12.5355 - MSLE: 0.0104\n",
      "Epoch 19/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.0657 - MSLE: 0.0085\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0096 - mean_absolute_percentage_error: 11.8239 - MSLE: 0.0096\n",
      "Epoch 20/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 9.9278 - MSLE: 0.0083\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0106 - mean_absolute_percentage_error: 12.2472 - MSLE: 0.0106\n",
      "Epoch 21/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_absolute_percentage_error: 9.9145 - MSLE: 0.0084\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0097 - mean_absolute_percentage_error: 12.2773 - MSLE: 0.0097\n",
      "Epoch 22/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_absolute_percentage_error: 9.7469 - MSLE: 0.0084\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0090 - mean_absolute_percentage_error: 11.8887 - MSLE: 0.0090\n",
      "Epoch 23/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0081 - mean_absolute_percentage_error: 9.7039 - MSLE: 0.0081\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0092 - mean_absolute_percentage_error: 11.6020 - MSLE: 0.0092\n",
      "Epoch 24/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.3842 - MSLE: 0.0085\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0091 - mean_absolute_percentage_error: 11.7930 - MSLE: 0.0091\n",
      "Epoch 25/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_absolute_percentage_error: 10.3172 - MSLE: 0.0084\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0091 - mean_absolute_percentage_error: 11.8910 - MSLE: 0.0091\n",
      "Epoch 26/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0081 - mean_absolute_percentage_error: 9.8111 - MSLE: 0.0081\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0086 - mean_absolute_percentage_error: 11.6265 - MSLE: 0.0086\n",
      "Epoch 27/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0080 - mean_absolute_percentage_error: 9.7404 - MSLE: 0.0080\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0089 - mean_absolute_percentage_error: 11.5924 - MSLE: 0.0089\n",
      "Epoch 28/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0082 - mean_absolute_percentage_error: 9.7387 - MSLE: 0.0082\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0085 - mean_absolute_percentage_error: 11.3511 - MSLE: 0.0085\n",
      "Epoch 29/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0087 - mean_absolute_percentage_error: 10.2532 - MSLE: 0.0087\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.8931 - MSLE: 0.0085\n",
      "Epoch 30/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 9.7613 - MSLE: 0.0083\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0082 - mean_absolute_percentage_error: 11.3349 - MSLE: 0.0082\n",
      "Epoch 31/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_percentage_error: 9.8822 - MSLE: 0.0085\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0081 - mean_absolute_percentage_error: 11.1176 - MSLE: 0.0081\n",
      "Epoch 32/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 9.7546 - MSLE: 0.0083\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0084 - mean_absolute_percentage_error: 11.1837 - MSLE: 0.0084\n",
      "Epoch 33/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0086 - mean_absolute_percentage_error: 10.0508 - MSLE: 0.0086\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0078 - mean_absolute_percentage_error: 11.2478 - MSLE: 0.0078\n",
      "Epoch 34/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_absolute_percentage_error: 9.8999 - MSLE: 0.0084\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0074 - mean_absolute_percentage_error: 10.5509 - MSLE: 0.0074\n",
      "Epoch 35/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 9.8724 - MSLE: 0.0083\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0074 - mean_absolute_percentage_error: 10.8892 - MSLE: 0.0074\n",
      "Epoch 36/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 9.8480 - MSLE: 0.0083\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0087 - mean_absolute_percentage_error: 11.2136 - MSLE: 0.0087\n",
      "Epoch 37/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.1408 - MSLE: 0.0085\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0080 - mean_absolute_percentage_error: 10.9390 - MSLE: 0.0080\n",
      "Epoch 38/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0082 - mean_absolute_percentage_error: 9.9143 - MSLE: 0.0082\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0081 - mean_absolute_percentage_error: 10.7596 - MSLE: 0.0081\n",
      "Epoch 39/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 10.0903 - MSLE: 0.0083\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0072 - mean_absolute_percentage_error: 10.5765 - MSLE: 0.0072\n",
      "Epoch 40/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0082 - mean_absolute_percentage_error: 9.8904 - MSLE: 0.0082\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0076 - mean_absolute_percentage_error: 11.0586 - MSLE: 0.0076\n",
      "Epoch 41/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0082 - mean_absolute_percentage_error: 9.8943 - MSLE: 0.0082\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0075 - mean_absolute_percentage_error: 10.5444 - MSLE: 0.0075\n",
      "Epoch 42/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0081 - mean_absolute_percentage_error: 9.7249 - MSLE: 0.0081\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0082 - mean_absolute_percentage_error: 10.8932 - MSLE: 0.0082\n",
      "Epoch 43/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.1161 - MSLE: 0.0085\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0070 - mean_absolute_percentage_error: 10.1956 - MSLE: 0.0070\n",
      "Epoch 44/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_absolute_percentage_error: 10.0913 - MSLE: 0.0084\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0072 - mean_absolute_percentage_error: 10.6233 - MSLE: 0.0072\n",
      "Epoch 45/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 10.0812 - MSLE: 0.0083\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0079 - mean_absolute_percentage_error: 11.1280 - MSLE: 0.0079\n",
      "Epoch 46/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0087 - mean_absolute_percentage_error: 10.3466 - MSLE: 0.0087\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0071 - mean_absolute_percentage_error: 10.4538 - MSLE: 0.0071\n",
      "Epoch 47/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0086 - mean_absolute_percentage_error: 10.2407 - MSLE: 0.0086\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0076 - mean_absolute_percentage_error: 10.6463 - MSLE: 0.0076\n",
      "Epoch 48/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 9.9546 - MSLE: 0.0083\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0070 - mean_absolute_percentage_error: 10.1156 - MSLE: 0.0070\n",
      "Epoch 49/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.0094 - MSLE: 0.0085\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0067 - mean_absolute_percentage_error: 9.9604 - MSLE: 0.0067\n",
      "Epoch 50/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_absolute_percentage_error: 9.8451 - MSLE: 0.0084\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0067 - mean_absolute_percentage_error: 10.0968 - MSLE: 0.0067\n",
      "Epoch 51/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_absolute_percentage_error: 9.9640 - MSLE: 0.0084\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0067 - mean_absolute_percentage_error: 10.0568 - MSLE: 0.0067\n",
      "Epoch 52/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0086 - mean_absolute_percentage_error: 10.3479 - MSLE: 0.0086\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0073 - mean_absolute_percentage_error: 10.5902 - MSLE: 0.0073\n",
      "Epoch 53/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.1397 - MSLE: 0.0085\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0066 - mean_absolute_percentage_error: 10.0401 - MSLE: 0.0066\n",
      "Epoch 54/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_absolute_percentage_error: 10.3291 - MSLE: 0.0088\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0070 - mean_absolute_percentage_error: 10.3628 - MSLE: 0.0070\n",
      "Epoch 55/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0091 - mean_absolute_percentage_error: 10.6405 - MSLE: 0.0091\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0063 - mean_absolute_percentage_error: 9.5311 - MSLE: 0.0063\n",
      "Epoch 56/80\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0087 - mean_absolute_percentage_error: 10.3654 - MSLE: 0.0087\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0061 - mean_absolute_percentage_error: 9.6973 - MSLE: 0.0061\n",
      "Epoch 57/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_absolute_percentage_error: 9.9273 - MSLE: 0.0084\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0059 - mean_absolute_percentage_error: 9.4370 - MSLE: 0.0059\n",
      "Epoch 58/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_absolute_percentage_error: 10.4824 - MSLE: 0.0088\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0066 - mean_absolute_percentage_error: 10.0065 - MSLE: 0.0066\n",
      "Epoch 59/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.1980 - MSLE: 0.0085\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0066 - mean_absolute_percentage_error: 9.8280 - MSLE: 0.0066\n",
      "Epoch 60/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0081 - mean_absolute_percentage_error: 9.8996 - MSLE: 0.0081\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0067 - mean_absolute_percentage_error: 9.7629 - MSLE: 0.0067\n",
      "Epoch 61/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0081 - mean_absolute_percentage_error: 9.9628 - MSLE: 0.0081\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0065 - mean_absolute_percentage_error: 9.8961 - MSLE: 0.0065\n",
      "Epoch 62/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0080 - mean_absolute_percentage_error: 9.8193 - MSLE: 0.0080\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0065 - mean_absolute_percentage_error: 9.9715 - MSLE: 0.0065\n",
      "Epoch 63/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0079 - mean_absolute_percentage_error: 9.8682 - MSLE: 0.0079\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0061 - mean_absolute_percentage_error: 9.3947 - MSLE: 0.0061\n",
      "Epoch 64/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0080 - mean_absolute_percentage_error: 9.9791 - MSLE: 0.0080\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0057 - mean_absolute_percentage_error: 9.4112 - MSLE: 0.0057\n",
      "Epoch 65/80\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0080 - mean_absolute_percentage_error: 9.9516 - MSLE: 0.0080\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0060 - mean_absolute_percentage_error: 9.6250 - MSLE: 0.0060\n",
      "Epoch 66/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0081 - mean_absolute_percentage_error: 10.0619 - MSLE: 0.0081\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.0058 - mean_absolute_percentage_error: 9.4256 - MSLE: 0.0058\n",
      "Epoch 67/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0080 - mean_absolute_percentage_error: 10.1495 - MSLE: 0.0080\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 9.2195 - MSLE: 0.0058\n",
      "Epoch 68/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0082 - mean_absolute_percentage_error: 10.0611 - MSLE: 0.0082\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0066 - mean_absolute_percentage_error: 9.7287 - MSLE: 0.0066\n",
      "Epoch 69/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 10.1521 - MSLE: 0.0083\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0055 - mean_absolute_percentage_error: 9.2937 - MSLE: 0.0055\n",
      "Epoch 70/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.1658 - MSLE: 0.0085\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0059 - mean_absolute_percentage_error: 9.2548 - MSLE: 0.0059\n",
      "Epoch 71/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0080 - mean_absolute_percentage_error: 9.9894 - MSLE: 0.0080\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0061 - mean_absolute_percentage_error: 9.4749 - MSLE: 0.0061\n",
      "Epoch 72/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0079 - mean_absolute_percentage_error: 9.8720 - MSLE: 0.0079\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0059 - mean_absolute_percentage_error: 9.1275 - MSLE: 0.0059\n",
      "Epoch 73/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0080 - mean_absolute_percentage_error: 9.8960 - MSLE: 0.0080\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0061 - mean_absolute_percentage_error: 9.2919 - MSLE: 0.0061\n",
      "Epoch 74/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 10.2665 - MSLE: 0.0083\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0054 - mean_absolute_percentage_error: 8.8899 - MSLE: 0.0054\n",
      "Epoch 75/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_percentage_error: 10.1265 - MSLE: 0.0085\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0062 - mean_absolute_percentage_error: 9.6401 - MSLE: 0.0062\n",
      "Epoch 76/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_absolute_percentage_error: 10.0494 - MSLE: 0.0083\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0054 - mean_absolute_percentage_error: 8.7724 - MSLE: 0.0054\n",
      "Epoch 77/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0079 - mean_absolute_percentage_error: 9.8198 - MSLE: 0.0079\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0054 - mean_absolute_percentage_error: 9.1521 - MSLE: 0.0054\n",
      "Epoch 78/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0082 - mean_absolute_percentage_error: 10.1223 - MSLE: 0.0082\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0046 - mean_absolute_percentage_error: 8.1604 - MSLE: 0.0046\n",
      "Epoch 79/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_absolute_percentage_error: 10.2004 - MSLE: 0.0084\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0055 - mean_absolute_percentage_error: 8.9147 - MSLE: 0.0055\n",
      "Epoch 80/80\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0080 - mean_absolute_percentage_error: 9.9773 - MSLE: 0.0080\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 8.8866 - MSLE: 0.0058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa53014c0f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "epochs_list = []\n",
    "model = first_model(preprocessing_model, inputs)\n",
    "model.fit(x=features_dict, y=labels, epochs=80, callbacks=[Callbacks()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the learning curves (the hyperparameters were tuned to minimize bias and variance based on this plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(epochs_list, train_losses, label='Train')\n",
    "plt.plot(epochs_list, test_losses, label='Test')\n",
    "plt.legend()\n",
    "plt.ylim([0,1.15 * max(train_losses[0], test_losses[0])])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('mean absolute percentage error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0080 - mean_absolute_percentage_error: 9.9773 - MSLE: 0.0080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.008023053407669067, 9.977315902709961, 0.008023053407669067]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_features_dict, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_features_dict) * 100000\n",
    "actual = test_labels * 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean squared logarithmic error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.141])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_sum = 0\n",
    "for i in range(len(preds)):\n",
    "    tot_sum += (np.log(preds[i] + 1) - np.log(actual[i] + 1)) ** 2\n",
    "np.sqrt(tot_sum / len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New model: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it seems like it will be hard to reduce our bias with a neural network, we will turn to another model: random forests. We will do the same date pre-processing, but this time using pandas, since we will Scikit learn and not keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Do the same preprocessing as with the other model\n",
    "\n",
    "full_data = pd.read_csv(\"./Data/train.csv\")\n",
    "\n",
    "year_cols=['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold']\n",
    "\n",
    "for col in year_cols:\n",
    "    full_data[col] = full_data[col].astype(str)\n",
    "\n",
    "cutoff = 7 * len(full_data) // 10\n",
    "\n",
    "train_data = full_data[:cutoff]\n",
    "features = train_data.copy()\n",
    "labels = np.array(features.pop('SalePrice'))\n",
    "features.pop('Id')\n",
    "\n",
    "test_data = full_data[cutoff:]\n",
    "test_features = test_data.copy()\n",
    "test_labels = np.array(test_features.pop('SalePrice'))\n",
    "test_features.pop('Id')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we do the preprocessing only using pandas, rather than the keras layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PandasPreprocessing(features, train_data):  \n",
    "    year_cols=['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold']\n",
    "    #Get years as strings\n",
    "    for col in year_cols:\n",
    "        train_data[col] = train_data[col].astype(str)\n",
    "    #Deal with missing data as before\n",
    "    for name, column in features.items():\n",
    "        dtype = column.dtype\n",
    "        if dtype == object:\n",
    "            features[name] = features[name].fillna('NO INFO')\n",
    "            train_data[name] = train_data[name].fillna('NO INFO')\n",
    "            enc = OneHotEncoder(handle_unknown='ignore')\n",
    "            enc.fit(train_data[name].to_numpy().reshape(-1, 1))\n",
    "            encoded_col = enc.transform(column.to_numpy().reshape(-1, 1)).toarray()\n",
    "            encoded_col = list(map(list, zip(*encoded_col)))\n",
    "            features.pop(name)\n",
    "            for i, col in enumerate(encoded_col):\n",
    "                features[name + '_' + str(i)] = col\n",
    "        else:\n",
    "            #No real need to normalize for tree based algorithms, just fill the nans with column mean\n",
    "            features[name] = features[name].fillna(features[name].mean(axis=0))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "features = PandasPreprocessing(features, train_data)\n",
    "test_features = PandasPreprocessing(test_features, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set values for the parameter grid we want to train our model over\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model over our random grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int)\n",
      "/home/mathieu/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/home/mathieu/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/home/mathieu/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  9.4min finished\n",
      "/home/mathieu/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:793: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators='warn',\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_sta...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor()\n",
    "regr_random = RandomizedSearchCV(estimator = regr, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "regr_random.fit(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best parameters in the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 80,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the models with the optimal parameters found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=80,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=5,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=600,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor(n_estimators = 600,\n",
    " min_samples_split = 5,\n",
    " min_samples_leaf = 1,\n",
    " max_features = 'auto',\n",
    " max_depth = 80,\n",
    " bootstrap = True)\n",
    "regr.fit(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/base.py:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "preds = regr.predict(test_features)\n",
    "actual = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15025485584369982"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_sum = 0\n",
    "for i in range(len(preds)):\n",
    "    tot_sum += (np.log(preds[i] + 1) - np.log(actual[i] + 1)) ** 2\n",
    "np.sqrt(tot_sum / len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that in this case, the RF model did not do better than the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
